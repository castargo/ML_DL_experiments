{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы оптимизации в нейронных сетях\n",
    "\n",
    "Обучая нейронную сеть, на самом деле, мы **решаем задачу оптимизации**: ищем такие аргументы (параметры или веса) нейронной сети, которые минимизируют выбранную функцию ошибки.\n",
    "\n",
    "Формализуем задачу: \n",
    "* Дано $N$ объектов $x_i$ ($|X| = N$) с ответами $y_i$\n",
    "* Объекты описаны векторами вещественных чисел: $x_i = (x_1, x_2, ..., x_d) \\in R^d$\n",
    "* Решающий алгоритм $a(x, \\theta)$ - многослойная нейронная сеть с K слоями\n",
    "* Каждый слой имеет свои параметры $\\theta_k$ - веса и смещения:\n",
    "    * Веса $W$ - матрица, размерность которой количество входов на количество выходов\n",
    "    * Смещения $b$ - вектор, размерности выходов\n",
    "\n",
    "> Чтобы посчитать количество оптимизируемых параметров $\\theta$ полносвязной нейронной сети для всех слоев $K$ складываем $\\text{dim}(W) + \\text{dim}(b)$\n",
    "\n",
    "Именно эти параметры мы должны оптимизировать так, чтобы наш алгоритм наилучшим образом решал поставленную задачу. Для этого, в зависимости от решаемой задачи, мы подбираем функцию ошибки $\\mathcal{L}(a(x_i, \\theta), y_i)$ и решаем задачу оптимизации:\n",
    "\n",
    "$$Q(\\theta) = Q(\\theta_1, \\theta_2, ..., \\theta_N) = \\sum\\limits_{i=1}^N \\mathcal{L}(a(x_i, \\theta), y_i) \\rightarrow \\min_\\theta$$\n",
    "\n",
    "$$\\theta = \\mathrm{argmin}_\\theta Q(\\theta_1, \\theta_2, ..., \\theta_N)$$\n",
    "\n",
    "Как можно видеть, оптимизируемая функция является сложной (композицией других функций), не задана в явном виде, более того, она может не быть выпуклой (в отличае от задачи оптимизации весов перцептрона).\n",
    "\n",
    "Существуют разные методы оптимизации, которые могут решить поставленную задачу (случайный перебор, метод отжига), однако, наибольшей популярностью пользуется **градиентный спуск** и его вариации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея метода градиентного спуска\n",
    "\n",
    "Суть работы градиентного спуска часто передают при помощи примера с человеком, который шагает вниз по склону холма. В этом примере холм состоит из значений функции ошибки от весов модели (такая вот трехмерная поверхность функции от двух аргументов), человек - текущее значение параметров, а то, куда он направляется - минимум функции ошибки.\n",
    "\n",
    "Прийти в этот минимум достаточно легко: нужно итеративно двигаться в сторону антиградиента функции ошибки, поскольку он указывает в направлении наискорейшего убывания функции:\n",
    "\n",
    "$$\n",
    "-\\nabla_{\\theta} Q=-\\left[\\begin{array}{c}\n",
    "\\dfrac{\\partial Q}{\\partial \\theta_1}\\\\\n",
    "\\dfrac{\\partial Q}{\\partial \\theta_2}\\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial Q}{\\partial \\theta_n}\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Тогда мы можем описать идею метода градиентного спуска как последовательность шагов:\n",
    "1. Инициализация весов $\\theta$: $W^{(0)}, b^{(0)}$\n",
    "2. Обновление весов $\\theta$ на шаге $i + 1$:\n",
    "    * $W^{(i+1)} = W^{(i)} - \\eta \\frac{\\partial Q}{\\partial W}$\n",
    "    * $b^{(i+1)} = b^{(i)} - \\eta \\frac{\\partial Q}{\\partial b}$\n",
    "\n",
    "В общем виде шаг градиентного спуска можно записать:\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - \\eta \\nabla_\\theta Q(\\theta^{(i)}) = \\theta^{(i)} - \\eta \\sum_{(x, y)} \\nabla_\\theta \\mathcal{L}(a(x, \\theta^{(i)}), y)$$\n",
    "\n",
    "$\\eta$ - learning rate, параметр градиентного спуска, который регулиует размер шага, который делает алгоритм в сторону антиградиента.\n",
    "\n",
    "Вычисления остановятся тогда, когда мы выполним заданное количество шагов или при срабатывании некоторого критерия остановки. Сложность задачи заключается в том, что функция потерь может иметь значительное число локальных минимумов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление производной по всем параметрам\n",
    "\n",
    "[Computing Neural Network Gradients](https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf)\n",
    "\n",
    "Для того, чтобы осуществить градиентный спуск, нам нужно знать производную функции потерь по всем параметрам нейронной сети: \n",
    "\n",
    "$$\\frac{\\partial Q}{\\partial \\theta_i}$$\n",
    "\n",
    "Однако, наша оптимизируемая функция является сложной функцией, то есть функцией от функций (композицией функций). Например, пусть $Q(\\theta) = f(g(\\theta))$. Тогда ее производную будем выичислять по правилу вычисления производной сложной функции ([chain rule](https://en.wikipedia.org/wiki/Chain_rule)):\n",
    "\n",
    "$$(f(g(\\theta)))' = f'(g(\\theta)) \\cdot g'(\\theta)$$\n",
    "\n",
    "Сложные функции можно визуализировать в виде **графа вычислений**. Его узлами являются функции, а ребрами - их аргументы. [Хороший пример здесь.](https://stepik.org/lesson/210594/step/6?unit=184089)\n",
    "\n",
    "В нашем случае $f$, $g$, $\\theta$ - векторные величины, тогда $f = f(g_1(\\theta), g_2(\\theta), ..., g_k(\\theta))$. Градиент по каждой отдельной компоненте:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta} g_i = \\begin{pmatrix}\n",
    "\\dfrac{\\partial g_i}{\\partial \\theta_1}\\\\\n",
    "\\vdots \\\\\n",
    "\\dfrac{\\partial g_i}{\\partial \\theta_n}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Тогда $\\nabla_{\\theta} g$ - матрица Якоби:\n",
    "\n",
    "$$\\nabla_{\\theta} g = \n",
    "\\begin{pmatrix}\n",
    "    \\dfrac{\\partial g_1}{\\partial \\theta_1}  & \\dots  & \\dfrac{\\partial g_k}{\\partial \\theta_1} \\\\\n",
    "    \\vdots  & \\ddots & \\vdots \\\\\n",
    "    \\dfrac{\\partial g_1}{\\partial \\theta_n}  & \\dots  & \\dfrac{\\partial g_k}{\\partial \\theta_n}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Тогда получается, что искомый градиент:\n",
    "\n",
    "$$\\nabla_{\\theta} f = \\nabla_{\\theta} g \\nabla_{g} f$$\n",
    "\n",
    "Будем искать частные производные функции ошибки по всем оптимизируемым параметрам нейронной сети от стоков к истокам, получая частные производные стоков по всем промежуточным узлам. Нам необходимо это, чтобы обновлять веса нейронной сети, а алгоритм, который лежит в основе метода называется **алгоритмом обратного распространения ошибки (back propagation)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм обучения нейронной сети\n",
    "\n",
    "0. Определить архитектуру нейронной сети (слои, активации и прочее) и функцию потерь $\\mathcal{L}$.\n",
    "1. Инициализировать параметры модели $\\theta$. Для простоты будем пока считать, что мы инициализировали их маленькими случайными числами.\n",
    "2. Итеративно прогонять объекты $x_i$ через нейронную сеть до наступления сходимости:\n",
    "    * **Прямое распространение (forward propagation):** для каждого слоя $k$ и его функции активации последовательно вычисляем $a_k(x_i, \\theta_k) = \\varphi_k(\\langle \\theta_k, x_i \\rangle) = \\varphi_k(x_i \\cdot W_k + b_k)$ передавая параметры из первого слоя сети в последующий (кстати, именно это мы будем делать, считая прогноз нейронной сети для некоторого объекта $x_j$);\n",
    "    * **Обратное распространение (back propagation):** вычисляем ошибку нейронной сети и корректируем параметры (веса и смещения), двигаясь от последнего слоя к первому;\n",
    "    * **Корректировка параметров (шаг градиентного спуска):** вычитаем из параметров на текущем шаге величину, на которую изменится вес связи - $\\nabla_\\theta Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск и его модификации\n",
    "\n",
    "Как прогонять объекты через нейронную сеть? Существует несколько наиболее распространенных модификаций алгоритма градиентного спуска:\n",
    "\n",
    "### \"Классический\" градиентный спуск\n",
    "\n",
    "В \"классическом\" алгоритме градиентного спуска, для того, чтобы сделать один шаг, необходимо пройти по всему тренировочному множеству с $N$ объектами:\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - \\eta \\nabla_\\theta Q(\\theta^{(i)}) = \\theta^{(i)} - \\eta \\sum_{j=1}^N \\nabla_\\theta \\mathcal{L}(a(x_j, \\theta^{(i)}), y_j)$$\n",
    "\n",
    "Таким образом, для одного шага градиентного спуска необходимо выполнить суммирование **по всем элементам** обучающей выборки, что будет достаточно долго при наличии большой выборки.\n",
    "\n",
    "### Stochastic gradient descent (SGD)\n",
    "\n",
    "> Стохастичность означает случайность.\n",
    "\n",
    "В алгоритме стохастического градиентного спуска мы случайно выбираем один объект из обучающей выборки и обновляем параметры после расчета градиента на этом примере. Это существенно ускоряет скорость обучения и снижает объем памяти, необходимый для хранения выборки на каждом шаге градиентного спуска, но из-за своей \"случайности\" он с большей вероятностью может \"застрять\" в локальном минимуме - график стохастического градиентного спуска в отличае от \"классического\" градиентного спуска будет очень \"дерганным\".\n",
    "\n",
    "### Stochastic average gradient descent (SAG)\n",
    "\n",
    "Это модификация стохастического градиентного спуска, в котором также сохраняется среднее значение по оптимизируемым параметрам, и после каждого шага $\\theta$ подменяется этим вектором средних.\n",
    "\n",
    "### Мini-batch gradient descent\n",
    "\n",
    "В этой модификации градиентного спуска из всех объектов обучающего множества поочередно случайно без повторений выбирается $M$ объектов (mini-batch), на которых вычисляется градиент.\n",
    "\n",
    "### На практике: torch.optim.SGD и torch.optim.ASGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизаторы\n",
    "\n",
    "[Оптимизация в ML](https://academy.yandex.ru/handbook/ml/article/optimizaciya-v-ml)\n",
    "\n",
    "К сожалению, на практике мы можем столкнуться с функциями потерь, которые могут иметь \"неудобную\" для нас форму, например, будут сильно вытянуты вдоль одной из своих осей. Тогда стохастический градиентый спуск будет очень медленно сходиться.\n",
    "\n",
    "Основная идея оптимизаторов, которые помогают бороться с этой проблемой, заключается в том, что мы начинаем использовать информацию с предыдущих шагов градиентного спуска.\n",
    "\n",
    "### Momentum (импульс)\n",
    "\n",
    "[Why Momentum Really Works](https://distill.pub/2017/momentum/)\n",
    "\n",
    "Momentum (импульс) - это экспоненциальное скользящее среднее (Exponential Moving Average, EMA) градиента по нескольким последним итерация. Фактически, мы просто добавляем параметр коэффициента импульса с множетелем $\\gamma$ - momentum factor. Тогда уравнение для разности параметров, которое мы используем в градиентном спуске, будет выглядеть следующим образом:\n",
    "\n",
    "$$u_t = \\gamma u_{t-1} + \\eta \\nabla_\\theta Q(\\theta^{(i)})$$\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - u_t$$\n",
    "\n",
    "Или\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - \\eta \\nabla_\\theta Q(\\theta^{(i)}) + \\gamma (\\theta^{(i)} - \\theta^{(i-1)})$$\n",
    "\n",
    "С точки зрения физики - это накопление инерции:\n",
    "\n",
    "<img src=\"pictures/sgd_momentum.png\" width=450 height=450 />\n",
    "\n",
    "### Nesterov accelerated gradient descent (NAGD)\n",
    "\n",
    "Метод Нестерова - это модификация метода, представленного выше, где мы пытаемся \"предугадать\", где мы окажемся при вычислении градиентного спуска на следующем шаге. Для этого будем вычислять градиент не в текущей точке, а в точке, в которую мы бы попали, следуя импульсу:\n",
    "\n",
    "$$u_t = \\gamma u_{t-1} + \\eta \\nabla_\\theta Q(\\theta^{(i)} - \\gamma u_{t-1})$$\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - u_t$$\n",
    "\n",
    "<img src=\"pictures/nesterov_momentum.jpg\" width=450 height=450 />\n",
    "\n",
    "Важно отметить, что метод Нестерова является методом оптимизации первого порядка. Существует также метод Ньютона, являющийся методом второго порядка (операется не на первую, а на вторую производную функции). Матрица производных второго порядка называется матрицей Гессе, и, к сожалению, обновлять ее вычислительно дорого. Смотри: torch.optim.LBFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизаторы (2)\n",
    "\n",
    "В предыдущей группе оптимизаторов скорость обучения была одинаковая, и шаг градиентного спуска зависел от значения градиента на текущем шаге. Но что, если на текущем шаге некоторые веса уже близки к своим локальным минимумам?\n",
    "\n",
    "Попробуем **адаптировать** скорость обучения для разных параметров функции $Q$ по-разному.\n",
    "\n",
    "### Adagrad\n",
    "\n",
    "Один из первых методов, являющихся адаптацией SGD. В его основе лежит идея, что шаг градиентного спуска должен быть меньше для тех параметров модели, которые более изменчивы. Тогда изменение параметра $\\theta_j$ на соответствующем шаге будет:\n",
    "\n",
    "$$\\theta_j^{(i+1)} = \\theta_j^{(i)} - \\frac{\\eta}{\\sqrt{(G_{jj}^{(i)}) + \\epsilon}} \\nabla_{\\theta_j} Q(\\theta^{(i)})$$\n",
    "\n",
    "где $\\epsilon$ - сглаживающий параметр (некоторое малое число), а $G_{jj}^{(i)}$ - диагональная матрица, зависящая от градиента функции по этому параметру на всех предыдущих шагах.\n",
    "\n",
    "$$G_{jj}^{(i)} = G_{jj}^{(i-1)} + (\\nabla_{\\theta_j} Q(\\theta^{(i)}))^2$$\n",
    "\n",
    "Получается, что адаптивный шаг для параметра $\\theta_j$: $\\frac{\\eta}{\\sqrt{(G_{jj}^{(i)}) + \\epsilon}}$\n",
    "\n",
    "Легко заметить, что в вычислении $G_{jj}^{(i)}$ присутствует квадрат, что означает, что скорость будет от шага к шагу только уменьшаться. Иногда это происходит слишком быстро.\n",
    "\n",
    "В pytorch: torch.optim.Adagrad\n",
    "\n",
    "### Adadelta\n",
    "\n",
    "Adadelta - это модификация метода Adagrad, в которой $G_{jj}^{(i)}$ считается не на всех предыдущих шагах, а лишь на нескольких последних. Делается это при помощи экспоненциального скользящего среднего.\n",
    "\n",
    "В pytorch: torch.optim.Adadelta\n",
    "\n",
    "### Rprop и RMSprop\n",
    "\n",
    "В основе идеи метода RMSprop лежит практически такая же идея, что и в Adadelta: будем использовать экспоненциальное скользящее среднее для обновления скорости по параметру функции $Q$. Эти методы были предложены почти одновременно разными авторами.\n",
    "\n",
    "RMSprop опирается на один из первых методов оптимизации, применяемый в нейронных сетях - [Rprop](https://en.wikipedia.org/wiki/Rprop). Его особенность заключается в том, что он учитывает только знак производной, а не ее величину. И если для некоторого параметра $\\theta_j$ вектор антиградиента постоянно указывает в одну сторону, то скорость в этом направлении можно увеличить.\n",
    "\n",
    "В pytorch: torch.optim.Rprop\n",
    "\n",
    "RMS - root mean squares - здесь это корень из экспоненциального скользящего среднего квадратов. Формула обновления весов будет выглядеть следующим образом:\n",
    "\n",
    "$$\\theta_j^{(i)} = \\theta_j^{(i-1)} - \\frac{\\eta}{\\sqrt{(G_{jj}^{(i)}) + \\epsilon}} \\nabla_{\\theta_j} Q(\\theta^{(i-1)})$$\n",
    "\n",
    "$$G_{jj}^{(i)} = \\gamma G_{jj}^{(i-1)} + (1 - \\gamma) (\\nabla_{\\theta_j} Q(\\theta^{(i-1)}))^2$$\n",
    "\n",
    "В pytorch: torch.optim.RMSprop\n",
    "\n",
    "### Adam (ADAptive Momentum)\n",
    "\n",
    "Группа методов оптимизации, которые комбинируют идеи, представленные выше. \n",
    "\n",
    "$$m_t = \\beta_1 m + (1 - \\beta_1) g_t$$\n",
    "\n",
    "$$v_t = \\beta_2 m + (1 - \\beta_2) g_t^2$$\n",
    "\n",
    "$$u_t = \\frac{\\eta}{\\sqrt{v + \\epsilon}} m_t$$\n",
    "\n",
    "$$\\theta^{(i+1)} = \\theta^{(i)} - u_t$$\n",
    "\n",
    "Принято считать, что это \"серебряная пуля\" алгоритмов оптимизации, так как есть набор параметров, который считается идеальным практически для любой задачи:\n",
    "* $\\eta$ = 3e-4 (Karpathy constant)\n",
    "* $\\beta_1 = 0.9$\n",
    "* $\\beta_2 = 0.999$\n",
    "\n",
    "В pytorch: \n",
    "* torch.optim.Adam\n",
    "* torch.optim.AdamW\n",
    "* torch.optim.SparseAdam\n",
    "* torch.optim.Adamax\n",
    "* torch.optim.NAdam\n",
    "* torch.optim.RAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST: numpy net VS Pytorch net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выгузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST(root='data/',\n",
    "              download=True,\n",
    "              train=True,\n",
    "              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor, label = mnist[0]\n",
    "image_tensor.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_tensor[0, 0:28, 0:28]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X, y = [], []\n",
    "\n",
    "for ind in range(N):\n",
    "    image_tensor, label = mnist[ind]\n",
    "    X.append(image_tensor.flatten().numpy())\n",
    "    y.append(label)\n",
    "\n",
    "X_train, X_test = np.split(np.array(X), [N * 8 // 10])\n",
    "y_train, y_test = np.split(np.array(y), [N * 8 // 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy net\n",
    "\n",
    "[Источник вдохновения: microsoft - AI-For-Beginners](https://github.com/microsoft/AI-For-Beginners/blob/main/lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, n_in, n_out):\n",
    "        self.W = np.random.normal(0, 0.05, (n_out, n_in))\n",
    "        self.dW = np.random.normal(0, 0.05, (n_out, n_in))\n",
    "        self.b = np.zeros((1, n_out))\n",
    "        self.db = np.zeros((1, n_out))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.dot(x, self.W.T) + self.b\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        dx = np.dot(dz, self.W) \n",
    "        self.dW = np.dot(dz.T, self.x)\n",
    "        self.db = dz.sum(axis=0)\n",
    "        return dx\n",
    "    \n",
    "    def update(self, lr):\n",
    "        self.W -= lr * self.dW\n",
    "        self.b -= lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def forward(self, x):\n",
    "        y = np.tanh(x)\n",
    "        self.y = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        return (1.0 - self.y ** 2) * dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, z):\n",
    "        self.z = z\n",
    "        zmax = z.max(axis=1, keepdims=True)\n",
    "        expz = np.exp(z - zmax)\n",
    "        Z = expz.sum(axis=1, keepdims=True)\n",
    "        return expz / Z\n",
    "\n",
    "    def backward(self, dp):\n",
    "        p = self.forward(self.z)\n",
    "        pdp = p * dp\n",
    "        return pdp - p * pdp.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def forward(self, p, y):\n",
    "        self.p = p\n",
    "        self.y = y\n",
    "        p_of_y = p[np.arange(len(y)), y]\n",
    "        log_prob = np.log(p_of_y)\n",
    "        return -log_prob.mean()\n",
    "\n",
    "    def backward(self,loss):\n",
    "        dlog_softmax = np.zeros_like(self.p)\n",
    "        dlog_softmax[np.arange(len(self.y)), self.y] -= 1.0 / len(self.y)\n",
    "        return dlog_softmax / self.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "    \n",
    "    def add(self,l):\n",
    "        self.layers.append(l)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self,z):\n",
    "        for l in self.layers[::-1]:\n",
    "            z = l.backward(z)\n",
    "        return z\n",
    "    \n",
    "    def update(self,lr):\n",
    "        for l in self.layers:\n",
    "            if 'update' in l.__dir__():\n",
    "                l.update(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(x, y, loss=CrossEntropyLoss()):\n",
    "    p = net.forward(x)\n",
    "    loss = loss.forward(p, y)\n",
    "    pred = np.argmax(p, axis=1)\n",
    "    accuracy = (pred == y).mean()\n",
    "    return round(loss, 3), round(accuracy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss = 0.407, accuracy = 0.871\n",
      "Test loss = 0.729, accuracy = 0.8\n",
      "\n",
      "Epoch: 2\n",
      "Train loss = 0.241, accuracy = 0.922\n",
      "Test loss = 0.729, accuracy = 0.79\n",
      "\n",
      "Epoch: 3\n",
      "Train loss = 0.145, accuracy = 0.958\n",
      "Test loss = 0.81, accuracy = 0.815\n",
      "\n",
      "Epoch: 4\n",
      "Train loss = 0.138, accuracy = 0.95\n",
      "Test loss = 0.865, accuracy = 0.825\n",
      "\n",
      "Epoch: 5\n",
      "Train loss = 0.086, accuracy = 0.968\n",
      "Test loss = 0.934, accuracy = 0.83\n",
      "\n",
      "Epoch: 6\n",
      "Train loss = 0.057, accuracy = 0.981\n",
      "Test loss = 0.981, accuracy = 0.805\n",
      "\n",
      "Epoch: 7\n",
      "Train loss = 0.019, accuracy = 0.994\n",
      "Test loss = 0.889, accuracy = 0.855\n",
      "\n",
      "Epoch: 8\n",
      "Train loss = 0.004, accuracy = 1.0\n",
      "Test loss = 0.867, accuracy = 0.86\n",
      "\n",
      "Epoch: 9\n",
      "Train loss = 0.003, accuracy = 1.0\n",
      "Test loss = 0.878, accuracy = 0.865\n",
      "\n",
      "Epoch: 10\n",
      "Train loss = 0.002, accuracy = 1.0\n",
      "Test loss = 0.882, accuracy = 0.87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.add(Linear(784, 392))\n",
    "net.add(Tanh())\n",
    "net.add(Linear(392, 196))\n",
    "net.add(Tanh())\n",
    "net.add(Linear(196, 10))\n",
    "net.add(Softmax())\n",
    "loss = CrossEntropyLoss()\n",
    "\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    for i in range(0, len(X_train), BATCH_SIZE):\n",
    "        xb = X_train[i : i + BATCH_SIZE]\n",
    "        yb = y_train[i : i + BATCH_SIZE]\n",
    "\n",
    "        p = net.forward(xb)\n",
    "        l = loss.forward(p, yb)\n",
    "        dp = loss.backward(l)\n",
    "        dx = net.backward(dp)\n",
    "        net.update(LEARNING_RATE)\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(\"Train loss = {}, accuracy = {}\".format(*get_metrics(X_train, y_train)))\n",
    "    print(\"Test loss = {}, accuracy = {}\\n\".format(*get_metrics(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392, 784), (1, 392))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].W.shape, net.layers[0].b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((196, 392), (1, 196))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[2].W.shape, net.layers[2].b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 196), (1, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[4].W.shape, net.layers[4].b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 392)\n",
    "        self.func1 = torch.nn.Tanh()\n",
    "        self.fc2 = torch.nn.Linear(392, 196)\n",
    "        self.func2 = torch.nn.Tanh()\n",
    "        self.fc3 = torch.nn.Linear(196, 10)\n",
    "        self.func3 = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.func1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.func2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.func3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_torch(x, y, loss=torch.nn.CrossEntropyLoss()):\n",
    "    output = net2(torch.from_numpy(x))\n",
    "    loss = criterion(output, torch.from_numpy(y)).item()\n",
    "    preds = np.argmax(output.detach().numpy(), axis=1)\n",
    "    acc = (preds == y).mean()\n",
    "    return round(loss, 3), round(acc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-161e89843a4a>:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.func3(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss = 2.115, accuracy = 0.396\n",
      "Test loss = 2.133, accuracy = 0.385\n",
      "\n",
      "Epoch: 2\n",
      "Train loss = 1.798, accuracy = 0.695\n",
      "Test loss = 1.815, accuracy = 0.71\n",
      "\n",
      "Epoch: 3\n",
      "Train loss = 1.678, accuracy = 0.816\n",
      "Test loss = 1.738, accuracy = 0.75\n",
      "\n",
      "Epoch: 4\n",
      "Train loss = 1.636, accuracy = 0.846\n",
      "Test loss = 1.715, accuracy = 0.785\n",
      "\n",
      "Epoch: 5\n",
      "Train loss = 1.579, accuracy = 0.915\n",
      "Test loss = 1.67, accuracy = 0.835\n",
      "\n",
      "Epoch: 6\n",
      "Train loss = 1.55, accuracy = 0.935\n",
      "Test loss = 1.639, accuracy = 0.87\n",
      "\n",
      "Epoch: 7\n",
      "Train loss = 1.535, accuracy = 0.94\n",
      "Test loss = 1.631, accuracy = 0.87\n",
      "\n",
      "Epoch: 8\n",
      "Train loss = 1.523, accuracy = 0.95\n",
      "Test loss = 1.624, accuracy = 0.87\n",
      "\n",
      "Epoch: 9\n",
      "Train loss = 1.514, accuracy = 0.96\n",
      "Test loss = 1.62, accuracy = 0.85\n",
      "\n",
      "Epoch: 10\n",
      "Train loss = 1.507, accuracy = 0.964\n",
      "Test loss = 1.619, accuracy = 0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net2 = MyNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    for i in range(0, len(X_train), BATCH_SIZE):\n",
    "        xb = torch.from_numpy(X_train[i : i + BATCH_SIZE])\n",
    "        yb = torch.from_numpy(y_train[i : i + BATCH_SIZE])\n",
    "\n",
    "        output = net2(xb)\n",
    "        loss = criterion(output, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(\"Train loss = {}, accuracy = {}\".format(*get_metrics_torch(X_train, y_train)))\n",
    "    print(\"Test loss = {}, accuracy = {}\\n\".format(*get_metrics_torch(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([392, 784]), torch.Size([392]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fc1.weight.shape, net2.fc1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([196, 392]), torch.Size([196]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fc2.weight.shape, net2.fc2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 196]), torch.Size([10]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fc3.weight.shape, net2.fc3.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386718"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in net2.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386718"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 392 + 392 + 392 * 196 + 196 + 196 * 10 + 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
