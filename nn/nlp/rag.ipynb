{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6299dfc3",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "* [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)\n",
    "* [Архитектура RAG: полный гайд](https://habr.com/ru/amp/publications/791034/)\n",
    "* [RAG (Retrieval Augmented Generation) — простое и понятное объяснение](https://habr.com/ru/articles/779526/)\n",
    "* RAG From Scratch\n",
    "    * [YouTube](https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x)\n",
    "    * [GitHub](https://github.com/langchain-ai/rag-from-scratch?tab=readme-ov-file)\n",
    "* [Evaluation of Retrieval-Augmented Generation: A Survey](https://arxiv.org/pdf/2405.07437)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d1ebed",
   "metadata": {},
   "source": [
    "## Компоненты RAG-системы\n",
    "\n",
    "RAG - это техника повышения точности и надежности LLM с использованием документов, полученных из внешних источников. \n",
    "\n",
    "Процесс генерации информации при помощи RAG выглядит следующим образом:\n",
    "1. Пользователь составляет **запрос**\n",
    "2. Запрос отправляется в **поисковик**\n",
    "    * Определяется процесс поиска и извлечения документов по запросу:\n",
    "        * **Векторная база данных** (индексирование)\n",
    "        * **Retrievals** (поиск)\n",
    "3. Извлеченные документы отправляются в **генератор**\n",
    "    * Комбинация входного запроса и извлеченных документов\n",
    "4. Итоговый ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646db265",
   "metadata": {},
   "source": [
    "## Формирование базы знаний\n",
    "\n",
    "> LangChain [Document Loaders](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/) и [Text Splitters](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)\n",
    "\n",
    "Правильно нарезаем базу знаний на чанки для базы данных\n",
    "* По символам? По абзацам? Логически? С перекрытием?\n",
    "* Важные параметры: количество чанков, размер чанка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd61b3",
   "metadata": {},
   "source": [
    "## Векторная база данных\n",
    "\n",
    "Векторные базы данных хранят векторы контекста (эмбеддинги). На основе такой базы знаний производится **семантический поиск**, который помогает определить, насколько документы релевантны запросу:\n",
    "* Какой эмбедер выбрать?\n",
    "* Нужно ли дообучать эмбедер?\n",
    "\n",
    "[Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)\n",
    "\n",
    "[encodechka](https://github.com/avidale/encodechka)\n",
    "    \n",
    "Примеры векторных баз:\n",
    "* FAISS\n",
    "* ChromaDB\n",
    "* QDrant\n",
    "* ElasticSearch\n",
    "* Weaviate\n",
    "* Milvus\n",
    "* Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0294ea",
   "metadata": {},
   "source": [
    "## Retrievals\n",
    "\n",
    "* [Ретриверы из langchain_community](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/retrievers)\n",
    "* [The Basics of AI-Powered (Vector) Search](https://cameronrwolfe.substack.com/p/the-basics-of-ai-powered-vector-search)\n",
    "* [Устройство поисковых систем: базовый поиск и инвертированный индекс](https://habr.com/ru/articles/545634/)\n",
    "\n",
    "Виды ретриверов:\n",
    "\n",
    "* **Dense Retriever (embdedding similarity)** - используют трансформеры, например, BERT. Сходство между закодированными векторами вычисляется при помощи близости (cosine similarity).\n",
    "    * Стандартный ретривер - косинусная близость вектора запроса и вектора документа\n",
    "* **Sparse Retriever (разряженные вектора)** - традиционные методы информационного поиска, основанные на частотности\n",
    "    * TF‑IDF ретривер\n",
    "    * BM25 ретривер\n",
    "\n",
    "Можно использовать какой-то определенный ретривер, а можно построить **ансамбль ретриверов** при помощи EnsembleRetriever:\n",
    "* Результаты работы всех ретриверов объединяются\n",
    "* Общий пул документов ранжируется, например, при помощи, Reciprocal Rank Fusion\n",
    "\n",
    "> **MultiQueryRetriever**: перефразируем запрос несколько раз, извлечем документы по всем перефразированным вопросам, затем отранжируем общий пул документов\n",
    "\n",
    "> **Knowledge Graph Retriever**: в дополнение к векторной базе данных также можно использовать граф знаний со связями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf1c4a",
   "metadata": {},
   "source": [
    "## Rank Fusion Techniques\n",
    "\n",
    "Вообще, очень важно в каком порядке LLM увидит результаты поиска. Чем выше наиболее релевантный документ, тем лучше будет финальная генерация. В случае использования одного ретривера выборка ранжируется по метрике этого ретривера. Если же ретриверов несколько, то нужно использовать **реранкер**.\n",
    "\n",
    "Внутри EnsembleRetriever используется Reciprocal Rank Fusion. Основная его идея - придать большее значение элементам, занимающим более высокие позиции в каждом индивидуальном наборе результатов поиска. Формула RRF: 1 / (k + rank), где rank - позиция элемента в конкретном поиске, а k - константа (по умолчанию k=60). Оценки для каждого элемента в разных наборах затем суммируются для получения итоговой оценки. Так мы избавляемся от привязки к метрике конкретного ретривера и подчеркиваем значимость наиболее высоко отранжированных элементов.\n",
    "\n",
    "Другие реранкеры:\n",
    "* Cohere Rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3343d",
   "metadata": {},
   "source": [
    "## RAG-Fusion: Multi-Query Retrieval + Reranker (Rank Fusion Techniques)\n",
    "\n",
    "[RAG-Fusion: Multi-Query Retrieval & Rank Fusion Techniques](https://docsbot.ai/article/advanced-rag-techniques-multiquery-and-rank-fusion)\n",
    "\n",
    "Что будет, если вместо простой функции ранжирования документов использовать ML-модель? Идея похожа на описанную в предыдущем пункте:\n",
    "* Будем формулировать несколько вариантов запроса пользователя\n",
    "* Искать по каждому запросу документы в базе данных\n",
    "* Ранжировать и объединять результаты при помощи **Cross-Encoder**\n",
    "\n",
    "Вообще, векторные базы данных используют Bi-encoder-ы, чтобы вычислить похожесть двух векторов. На вход Bi-encoder принимает 1 документ и преобразует его в вектор. Тогда схема работы RAG-системы с Bi-encoder выглядит так:\n",
    "```\n",
    "Текст А --> BERT преобразование в вектор --> косинусная мера близости <-- BERT преобразование в вектор <-- Текст Б\n",
    "```\n",
    "\n",
    "Cross-Encoder принимает на вход 2 документа и возвращает их релевантность (similarity) относительно друг друга. Схема работы Cross-Encoder выглядит иначе:\n",
    "```\n",
    "Текст А, Текст Б --> BERT --> Классификатор --> Релевантность 0..1\n",
    "```\n",
    "\n",
    "Точность работы Cross-Encoder, как правило, выше, чем у Bi-encoder. Идея заключается в том, чтобы извлечь из базы побольше результатов, а затем отранжировать их при помощи Cross-Encoder и вернуть на вход LLM 3-5 из них.\n",
    "\n",
    "> **Интент-классификатор**: можно классифицировать документы на вопросы, жалобы, просьбы и т.д. Если данных для задачи нет совсем, обращаемся к LLM с промптом: Определи, к какой категории относится сообщение пользователя {user message}. Варианты категорий: вопрос, жалоба, просьба. Выбери и выведи строго из указанных категорий, не меняй формулировку категории."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d6400",
   "metadata": {},
   "source": [
    "## Дообучение LLM\n",
    "\n",
    "В задаче RAG на вход LLM поступают пары сущностей: входной запрос и контекст, состоящий из документов. LLM можно натюнить на такой вход."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038eee0",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Language Model based Prediction\n",
    "\n",
    "Будем на шаге поиска вместо обычно передачи результатов на генерацию, генерировать примеры ответов для LLM (few-shot prompting), заставляя ее динамически обучаться отвечать на поставленный вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb092af",
   "metadata": {},
   "source": [
    "## Промпт-инжениринг\n",
    "\n",
    "#### Корректный системный промпт\n",
    "\n",
    "Источник: [GigaChain работа с промптами](https://github.com/ai-forever/gigachain/tree/master/hub/prompts)\n",
    "\n",
    "```\n",
    "input_variables: []\n",
    "output_parser: null\n",
    "template: 'Ты - система информационного поиска. Тебе дан вопрос и релевантные отрывки текста из нескольких документов.\n",
    "Создай краткий и информативный ответ (не более 150 слов) на заданный вопрос,\n",
    "основываясь исключительно на приведенных отрывках документов. Ты должна использовать только информацию из приведенных отрывков.\n",
    "Используй непредвзятый и журналистский тон. Не повторяй текст.\n",
    "Создай окончательный ответ (\"FINAL ANSWER\").\n",
    "Не пытайся придумать ответ.\n",
    "Отвечай только на русском языке за исключением специальных терминов.\n",
    "Если документы не содержат ответа на вопрос, скажи, что \"Я не могу ответить на вопрос на основе информации. Попробуйте переформулировать вопрос.\"\n",
    "template_format: f-string\n",
    "_type: prompt\n",
    "```\n",
    "\n",
    "#### Пользовательский промпт\n",
    "\n",
    "```\n",
    "input_variables: [question, summaries]\n",
    "output_parser: null\n",
    "template: \"QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER:\"\n",
    "template_format: f-string\n",
    "_type: prompt\n",
    "```\n",
    "\n",
    "#### Промпт для обработки первоначального запроса пользователя\n",
    "\n",
    "```\n",
    "Вот запрос пользователя. Думай по шагам и оцени, что пользователь хотел узнать.\n",
    "В качестве ответа выведи настоящий запрос, который хотел ввести пользователь.\n",
    "```\n",
    "\n",
    "#### Промпт для суммаризации документа\n",
    "\n",
    "Если по запросу найдено много длинных чанков, можно попосить LLM суммаризовать каждый из нейденных чанков.\n",
    "\n",
    "> ConversationSummaryMemory\n",
    "\n",
    "#### Промпт для ранжирования результатов\n",
    "\n",
    "Вместо использования реранкера можно попросить LLM отранжировать документы в контексте.\n",
    "\n",
    "#### Промпт для реврайта\n",
    "\n",
    "На выходе можно попросить LLM вывести сгенерированный результат в определенном формате."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee3bf2",
   "metadata": {},
   "source": [
    "## Метрики оценки RAG-системы\n",
    "\n",
    "#### Формируем выборку для оценки\n",
    "\n",
    "**Golden set** (вопросы и ответы) должен быть составлен при помощи естественного интеллекта. Лучше всего, если будет несколько экземпляров ответов на один вопрос. RAG-система должна корректно и одинаково отвечать на вопрос, вне зависимости от его формулировки.\n",
    "\n",
    "#### Метрики поиска (ранжирования)\n",
    "\n",
    "Не учитывающие порядок:\n",
    "* Precision@K (P@K)\n",
    "\n",
    "Учитывающие порядок:\n",
    "* MRR@K\n",
    "* MAP@K\n",
    "* NDCG@K\n",
    "\n",
    "#### Метрики генерации\n",
    "\n",
    "ROUGE, BERTScore, BARTScore, BLEURT, METEOR. Можно написать взвешенную сумму перечисленных метрик.\n",
    "\n",
    "А еще можно попросить LLM вернуть не сгенерированные токены, а их логиты, и оценить, насколько она сама уверена в ответе (token level uncertainty).\n",
    "\n",
    "#### Retrieval Augmented Generation Automated Scoring (RAGAS)\n",
    "\n",
    "* [Оцениваем RAG-пайплайны](https://habr.com/ru/articles/778166/)\n",
    "* [Как сделать чат-бота лучше, нужен всего лишь простой советский… RAGAS](https://habr.com/ru/articles/787940/)\n",
    "* [GPT или GigaChat — ответит RAGAS](https://habr.com/ru/articles/794022/)\n",
    "\n",
    "[RAGAS](https://github.com/explodinggradients/ragas) - метод автоматизированной оценки RAG-системы. Оценивает одновременно и извлечение, и генерацию.\n",
    "\n",
    "Для оценки работы RAGAS используются специально сгенерированные тестовые данные. Эти данные должны включать в себя не только задачи извлечения фактов из документа, но цепочки рассуждения, понимание контекста и т.п.\n",
    "\n",
    "[Метрики RAGAS](https://github.com/explodinggradients/ragas/tree/main/src/ragas/metrics):\n",
    "* Оценка извлечения\n",
    "    * **context_precision**: насколько точно и релевантно использована информация из контекста\n",
    "    * **context_recall**: сколько информации из контекста использовано в ответе\n",
    "    * **context_entities_recall**: сколько релевантных токенов из контекста использовано в ответе\n",
    "    * **context_relevancy**: для ответа выбран релевантный контекст\n",
    "* Оценка генерации\n",
    "    * **faithfulness**: ответы излечены из документов\n",
    "    * **answer_relevance**: ответы соответствуют заданным вопросам\n",
    "    * **answer_correctness**: насколько ответ является правильным\n",
    "    * **answer_similarity**: насколько ответ RAG-системы близок к эталонному ответу\n",
    "\n",
    "#### Получение обратной связи от пользователей\n",
    "\n",
    "* Лайки/дизлайки\n",
    "* AB-тест"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863237f7",
   "metadata": {},
   "source": [
    "## Проблемы в RAG-системах и способы их решения\n",
    "\n",
    "* [12 RAG Pain Points and Solutions](https://originshq.com/blog/12-rag-pain-points-and-solutions/)\n",
    "* [Seven Failure Points When Engineering a Retrieval Augmented Generation System](https://arxiv.org/pdf/2401.05856)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbd996",
   "metadata": {},
   "source": [
    "## Модификации RAG\n",
    "\n",
    "* CRAG: [Corrective Retrieval Augmented Generation](https://arxiv.org/abs/2401.15884)\n",
    "* Self-RAG: [Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511)\n",
    "* FLARE: [Active Retrieval Augmented Generation](https://arxiv.org/abs/2305.06983)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
