{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc3bb53e",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "* [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)\n",
    "* [RAG From Scratch](https://github.com/langchain-ai/rag-from-scratch?tab=readme-ov-file)\n",
    "* [12 RAG Pain Points and Solutions](https://originshq.com/blog/12-rag-pain-points-and-solutions/)\n",
    "* [Seven Failure Points When Engineering a Retrieval Augmented Generation System](https://arxiv.org/pdf/2401.05856)\n",
    "* [Архитектура RAG: полный гайд](https://habr.com/ru/amp/publications/791034/)\n",
    "* [RAG (Retrieval Augmented Generation) — простое и понятное объяснение](https://habr.com/ru/articles/779526/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c95719",
   "metadata": {},
   "source": [
    "## Интро\n",
    "\n",
    "RAG - это техника повышения точности и надежности LLM с использованием документов, полученных из внешних источников. \n",
    "\n",
    "Процесс генерации информации при помощи RAG выглядит следующим образом:\n",
    "1. Пользователь составляет **запрос**\n",
    "2. Запрос отправляется в **поисковик**\n",
    "    * Определяется процесс поиска и извлечения документов по запросу:\n",
    "        * **Retrievals**\n",
    "        * **Векторная база данных**\n",
    "3. Извлеченные документы отправляются в **генератор**\n",
    "    * Комбинация входного запроса и извлеченных документов\n",
    "4. Итоговый ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb80ba",
   "metadata": {},
   "source": [
    "## Векторная база данных\n",
    "\n",
    "Векторные базы данных хранят векторы контекста (эмбеддинги). На основе такой базы знаний производится **семантический поиск**, который помогает определить, насколько документы релевантны запросу.\n",
    "\n",
    "1. Правильно нарезаем базу знаний на чанки для базы данных\n",
    "    * По символам? По абзацам? Логически? С перекрытием?\n",
    "    * Важные параметры: количество чанков, размер чанка\n",
    "2. Какой эмбедер выбрать\n",
    "    * Нужно ли его дообучать?\n",
    "    \n",
    "Примеры векторных баз:\n",
    "* Pinecone\n",
    "* ChromaDB\n",
    "* Weaviate\n",
    "* ElasticSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8544b175",
   "metadata": {},
   "source": [
    "## Retrievals\n",
    "\n",
    "* Стандартный ретривер - косинусная близость вектора запроса и вектора документа\n",
    "* BM25 ретривер\n",
    "* TF‑IDF ретривер\n",
    "* KNN ретривер\n",
    "\n",
    "[Ретриверы из langchain_community](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/retrievers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5023c",
   "metadata": {},
   "source": [
    "## MultiQuery\n",
    "\n",
    "Перефразирование запроса несколько раз, извлечение документов, затем обработка всего пула документов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273e1c2",
   "metadata": {},
   "source": [
    "## Дообучение LLM\n",
    "\n",
    "В задаче RAG на вход LLM поступают пары сущностей: входной запрос и контекст, состоящий из документов.\n",
    "\n",
    "LLM можно натюнить на такой вход."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456519dd",
   "metadata": {},
   "source": [
    "## Промпт-инженеринг\n",
    "\n",
    "### Промпт для обработки первоначального запроса пользователя\n",
    "\n",
    "```\n",
    "Вот запрос пользователя. Думай по шагам и оцени, что пользователь хотел узнать.\n",
    "В качестве ответа выведи настоящий запрос, который хотел ввести пользователь.\n",
    "```\n",
    "\n",
    "### Промпт для суммаризации документа\n",
    "\n",
    "Если по запросу найдено много длинных чанков, можно попосить LLM суммаризовать каждый из нейденных чанков.\n",
    "\n",
    "### Корректный системный промпт\n",
    "\n",
    "Источник: [GigaChain работа с промптами](https://github.com/ai-forever/gigachain/tree/master/hub/prompts)\n",
    "\n",
    "```\n",
    "input_variables: []\n",
    "output_parser: null\n",
    "template: 'Ты - система информационного поиска. Тебе дан вопрос и релевантные отрывки текста из нескольких документов.\n",
    "Создай краткий и информативный ответ (не более 150 слов) на заданный вопрос,\n",
    "основываясь исключительно на приведенных отрывках документов. Ты должна использовать только информацию из приведенных отрывков.\n",
    "Используй непредвзятый и журналистский тон. Не повторяй текст.\n",
    "Создай окончательный ответ (\"FINAL ANSWER\").\n",
    "Не пытайся придумать ответ.\n",
    "Отвечай только на русском языке за исключением специальных терминов.\n",
    "Если документы не содержат ответа на вопрос, скажи, что \"Я не могу ответить на вопрос на основе информации. Попробуйте переформулировать вопрос.\"\n",
    "template_format: f-string\n",
    "_type: prompt\n",
    "```\n",
    "\n",
    "### Пользовательский промпт\n",
    "\n",
    "```\n",
    "input_variables: [question, summaries]\n",
    "output_parser: null\n",
    "template: \"QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "FINAL ANSWER:\"\n",
    "template_format: f-string\n",
    "_type: prompt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47900e20",
   "metadata": {},
   "source": [
    "## Метрики оценки RAG-системы\n",
    "\n",
    "1. **Golden set** (вопросы и ответы) должен быть составлен при помощи естественного интеллекта. Лучше всего, если будет несколько экземпляров ответов на один вопрос.\n",
    "2. В задаче важно измерять отдельно:\n",
    "    * Метрики поиска (ранжирования)\n",
    "    * Метрики генерации\n",
    "        * ROUGE, BERTScore, BLEURT, METEOR. Можно написать взвешенную сумму перечисленных метрик."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
