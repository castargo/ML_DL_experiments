{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теорема Байеса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Литература\n",
    "* \"Глубокое обучение. Погружение в мир нейронных сетей\" - Николенко, Кадурин, Архангельская\n",
    "* [Понимаем теорему Байеса](https://habr.com/ru/company/otus/blog/473468/)\n",
    "* [Bayes' Theorem Intuition](https://stats.stackexchange.com/questions/239014/bayes-theorem-intuition)\n",
    "* [Теорема Байеса: Святой Грааль Data Science](https://proglib.io/p/bayes-theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы\n",
    "\n",
    "Априорная вероятность - вероятность, которая может быть измерена при любом состоянии окружающего мира:\n",
    "* $p(A)$ - априорная вероятность события $A$\n",
    "* $p(B)$ - априорная вероятность события $B$\n",
    "\n",
    "Совместная вероятность событий $p(A,B)$ - вероятность одновременного наступления двух событий. Если события $A$ и $B$ независимы, то, по определению, для них справедливо: $p(A,B) = p(A)p(B)$\n",
    "\n",
    "Условная независимость - вероятность наступления одного события, если известно, что произошло другое: $p(A | B) = \\frac{p(A,B)}{P(B)}$. $p(A | B)$ - условная (апостериорная) вероятность, измеряющая вероятность какого-то определенного состояния окружающего мира (а именно состояния, при котором произошло событие В).\n",
    "\n",
    "По определению условной вероятности: $p(A,B) = p(A | B)p(B) = p(B | A)P(A)$\n",
    "\n",
    "**Теорема Байеса**: \n",
    "$$ p(B | A) = \\frac{p(A | B)p(B)}{p(A)} = \\frac{p(A | B)p(B)}{\\sum_{B_i \\in B}p(A | B_i)p(B_i)}$$\n",
    "где:\n",
    "* $B_i$ - гипотезы, вероятности которых известны до проведения эксперимента (априорны)\n",
    "* Опыт проведен, в результате него произошло событие $A$\n",
    "* Требуется пересчитать вероятность гипотез в связи с появлением этого события, то есть определить апостериорные вероятности гипотез $B_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объяснение\n",
    "\n",
    "Пусть нам дано:\n",
    "* Hypothesis - априорная гипотеза\n",
    "* Evidence - доказательства или наблюдаемые факты\n",
    "\n",
    "Необходимо найти вероятность того, что гипотеза верна, с учетом наблюдаемых фактов.\n",
    "\n",
    "    Теорема Байеса:\n",
    "\n",
    "    p(Hypothesis | Evidence) = \n",
    "    = p(Hypothesis) * p(Evidence | Hypothesis) / p(Evidence) =\n",
    "    = Joint probability / Normalizer = \n",
    "    = Prior * Scaler / Normalizer\n",
    "\n",
    "P(Evidence|Hypothesis) - вероятность наступления событий-доказательств при условии, что гипотеза верна. Эту величину можно рассматривать как Scaler - когда мы умножаем его на априорное значение, он уменьшает или увеличивает вероятность события, в зависимости от того «вредит» ли какое-либо событие-доказательство гипотезе. Например, чем больше дней проходит без звонка с оффером, тем меньше вероятность того, что вас позовут на работу. Это необходимо для корректировки суждений.\n",
    "\n",
    "P(Evidence|Hypothesis) легче оценить, чем P(Hypothesis|Evidence), так как P(Evidence|Hypothesis) – более ограниченная область суждений о мире. Сужая область, мы упрощаем задачу. Можно провести аналогию с огнем и дымом, где огонь – наша гипотеза, а наблюдение дыма – событие, доказывающее наличие огня. P(огонь|дым) оценить сложнее, поскольку много чего может вызвать дым – выхлопные газы автомобилей, фабрики, человек, который жарит гамбургеры на углях. При этом P(дым|огонь) оценить проще, поскольку если есть огонь, то, почти наверняка, будет и дым.\n",
    "\n",
    "P(Evidence) – Normalizer. Joint probability = p(Hypothesis) * p(Evidence | Hypothesis) = Prior * Scaler. Поскольку одно из составляющих в нем P(Evidence), то на совместную вероятность повлияла бы маленькая частота событий. Деление на P(Evidence) помогает перейти от совместной вероятности к условной (апостериорной) вероятности. Условная вероятность учитывает только те состояния мира, в которых произошло событие-доказательство.\n",
    "\n",
    "Байесовский вывод – это метод, в котором теорема Байеса используется для обновления вероятности гипотезы по мере получения дополнительных подтверждений или иной информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теорема Байеса в машинном обучении\n",
    "\n",
    "Задача машинного обучения:\n",
    "* Дано: данные $D$\n",
    "* Необходимо для некоторой модели машинного обучения подобрать наилучшим образом (оптимизировать) вектор параметров $\\theta$, то есть оценить вероятность $p(\\theta | D)$ (но не наоборот!). \n",
    "\n",
    "Теорему Байеса используется для перехода от $p(\\theta | D)$ (которую непонятно, как считать) к $p(D | \\theta)$ (которая определяется в модели) и $p(\\theta)$ (которую мы задаем сами):\n",
    "\n",
    "$$ p(\\theta | D) = \\frac{p(D | \\theta)p(\\theta)}{p(D)} = \\frac{p(D | \\theta)p(\\theta)}{\\int_{\\theta \\in \\Theta}p(D | \\theta)p(\\theta) d\\theta}$$\n",
    "\n",
    "где:\n",
    "* $p(\\theta)$ - априорная вероятность (prior probability)\n",
    "* $p(D | \\theta)$ - правдоподобие (likelihood)\n",
    "* $p(\\theta | D)$ - апостериорная вероятность (posterior probability)\n",
    "* $p(D) = \\int p(D | \\theta)p(\\theta) d\\theta$ - вероятность данных (evidence)\n",
    "\n",
    "Обучение практически любой модели машинного обучения сводится либо к одной из двух задач:\n",
    "* Оптимизации правдоподобия $\\theta_{ML}$\n",
    "* Оптимизации апостериорного распределения $\\theta_{MAP}$\n",
    "\n",
    "### Оценка параметров в классической статистике\n",
    "\n",
    "В классической статистике опираются на **гипотезу максимального правдоподобия (maximum likelihood, ML)**, тогда задача сводится к максимизации правдоподобия:\n",
    "\n",
    "$$\\theta_{ML} = arg max_{\\theta} p(D | \\theta),$$\n",
    "\n",
    "где $arg max_{\\theta} f(\\theta)$ - значение вектора $\\theta$, на котором достигается максимум функции $f(\\theta)$.\n",
    "\n",
    "### Оценка параметров в байесовском подходе\n",
    "\n",
    "В байесовском подходе и современном машинном обучении оценивают **апостериорное распределение (posterior)**:\n",
    "\n",
    "$$p(\\theta | D) \\propto p(D | \\theta)p(\\theta),$$\n",
    "\n",
    "Для максимизации **максимальной апостериорной гипотезы (maximum a posteriori hypothesis, MAP)**:\n",
    "\n",
    "$$\\theta_{MAP} = arg max_{\\theta} p(\\theta | D) = arg max_{\\theta} p(D | \\theta)p(\\theta)$$\n",
    "\n",
    "**Замечание**: знак пропорциональности ($\\propto$) пропадает тогда, когда мы нормализуем результат. В формуле вычисления $\\theta_{MAP}$ это происходит \"за кадром\", так как мы явно не говорим, что используем нормировочную константу $\\int p(D|\\theta)p(\\theta)d\\theta$, так как она не зависит от $\\theta$.\n",
    "\n",
    "Будем пологать, что каждая точка данных $d$ была порождена описанным в модели процессом независимо, то есть правдоподобие набора данных $D$ будет представлять собой произведение по всем точкам: $p(D | \\theta) = \\prod\\limits_{d \\in D} p(d | \\theta)$. \n",
    "\n",
    "\n",
    "Поэтому для оценки $\\theta_{MAP}$ мы можем перейти от произведения к логарифму суммы:\n",
    "\n",
    "$$\\theta_{MAP} = arg max_{\\theta} p(D | \\theta)p(\\theta) = arg max_{\\theta} p(\\theta) \\prod\\limits_{d \\in D} p(d | \\theta) = arg max_{\\theta} (log(p(\\theta)) + \\sum\\limits_{d \\in D} log(p(d | \\theta)))$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
