{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проблема переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Литература\n",
    "\n",
    "* Специализация \"Машинное обучение и анализ данных\" от МФТИ и Яндекса на Coursera\n",
    "* [Открытый курс машинного обучения. Тема 4. Линейные модели классификации и регрессии](https://habr.com/ru/companies/ods/articles/323890/)\n",
    "* [Перевод книги Эндрю Ына «Страсть к машинному обучению» Главы 20 — 27](https://habr.com/ru/post/420591/)\n",
    "* [Смещение (bias) и разброс (variance) (Дьяконов)](https://alexanderdyakonov.wordpress.com/2018/04/25/%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D0%B5-bias-%D0%B8-%D1%80%D0%B0%D0%B7%D0%B1%D1%80%D0%BE%D1%81-variance-%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8-%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82/)\n",
    "* [Шум, смещение и разброс (Щуров)](http://math-info.hse.ru/math-ml/chapter/label/chap:4:bias-variance/#:~:text=%D0%A8%D1%83%D0%BC%20%D1%80%D0%B0%D0%B2%D0%B5%D0%BD%20%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%B5%D0%BC%D0%BE%D0%B9%20%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B5%20%D0%B8%D0%B4%D0%B5%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE,%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D0%B0%20%D0%BF%D0%BE%20%D0%BE%D1%82%D0%BD%D0%BE%D1%88%D0%B5%D0%BD%D0%B8%D1%8E%20%D0%BA%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%BC.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ошибка алгоритма на тестовых данных\n",
    "\n",
    "Ошибка алгоритма на тестовых данных может быть разложена на 3 компоненты:         \n",
    "#### **Ошибка = Шум + Смещение + Разброс**\n",
    "* **Шум** - ошибка, которая отражает характеристику данных, погрешности измерений;\n",
    "* **Смещение (bias)** - отклонение усредненного прогноза  от прогноза идеальной модели;\n",
    "* **Разброс (variance)** - дисперсия ответов модели (зависимость прогноза алгоритма от выборки);\n",
    "\n",
    "Такое разложение в англоязычной литературе называют **bias-variance decomposition**.\n",
    "\n",
    "Как правило, принято пренебрегать компонентой \"шума\", ведь с ним мало что можно сделать.\n",
    "\n",
    "Для визуализации смещения и разброса часто используют это каноничное изображение:\n",
    "\n",
    "<img src=\"pictures/prec_acc.png\" width=400 height=400 />\n",
    "\n",
    "В задачах, где необходимо восстановить нелинейные зависимости:\n",
    "* Линейная модель: большое смещение (не может восстановить зависимость) и низкий разброс;\n",
    "* Решающие деревья: низкое смещение и большой разброс;\n",
    "* Случайный лес: низкое смещение (усреднение алгоритмов не меняет смещение) и низкий разброс (чем меньше корреляция между деревьями, тем ниже разброс);\n",
    "\n",
    "Визуализация разложения ошибки на смещение и разброс на примере усреднения нескольких базовых алгоритмов с низким смещением и большим разбросом, решающих задачу регрессии:\n",
    "\n",
    "<img src=\"pictures/bias_variance.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Математические выкладки ошибки модели в точке $\\vec{x}$\n",
    "\n",
    "$$\\text{Err}(\\vec{x}) = \\mathbb{E}[(y - \\hat{f}(\\vec{x}))^2] = $$\n",
    "$$ = \\mathbb{E}[y^2] + \\mathbb{E}[(\\hat{f}(\\vec{x}))^2] - 2\\mathbb{E}[y\\hat{f}(\\vec{x})] = $$\n",
    "$$ = \\sigma^2 + f^2 + \\text{Var}(\\hat{f}) + \\mathbb{E}[\\hat{f}]^2 - 2f\\mathbb{E}[\\hat{f}] = $$\n",
    "$$ = (f - \\mathbb{E}[\\hat{f}])^2 + \\text{Var}(\\hat{f}) + \\sigma^2 = $$\n",
    "$$ = \\text{Bias}(\\hat{f})^2 + \\text{Var}(\\hat{f}) + \\sigma^2$$\n",
    "\n",
    "Где:\n",
    " * $\\mathbb{E}[y^2] = \\text{Var}(y) + \\mathbb{E}[y]^2 = \\sigma^2 + f^2$\n",
    " * $\\mathbb{E}[\\hat{f}^2] = \\text{Var}(\\hat{f}) + \\mathbb{E}[\\hat{f}]^2$\n",
    " * $\\mathbb{E}[y\\hat{f}] = \\mathbb{E}[(f + \\epsilon)\\hat{f}] = \\mathbb{E}[f\\hat{f}] + \\mathbb{E}[\\epsilon\\hat{f}] = f\\mathbb{E}[\\hat{f}] + \\mathbb{E}[\\epsilon] \\mathbb{E}[\\hat{f}] = f\\mathbb{E}[\\hat{f}]$\n",
    " \n",
    "Таким образом, ошибка прогноза любой модели вида $y = f(\\vec{x}) + \\epsilon$ складывается из:\n",
    "* **Квадрат смещения**: $\\text{Bias}(\\hat{f})$ – средняя ошибка по всевозможным наборам данных\n",
    "* **Дисперсия**: $\\text{Var}(\\hat{f})$ – вариативность ошибки; насколько она будет отличаться, если обучать модель на разных наборах данных\n",
    "* **Шум**: \"особенность\" данных $\\sigma^2$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
